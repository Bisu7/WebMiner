{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0caf6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to download sample e-commerce pages for model training...\n",
      "Using synthetic data for demonstration purposes...\n",
      "Generated synthetic HTML for 5 e-commerce site types\n",
      "Generating training features from HTML structures...\n",
      "Generated 100 training samples\n",
      "Positive examples (product containers): 85\n",
      "Negative examples (non-product elements): 15\n",
      "Performing feature engineering...\n",
      "Training set size: 80\n",
      "Testing set size: 20\n",
      "Training Random Forest classifier...\n",
      "\n",
      "Model Evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n",
      "Saving model and feature engineering components...\n",
      "\n",
      "Top 10 most important features:\n",
      "             feature  importance\n",
      "52      html_feat_35    0.092558\n",
      "83      class_feat_0    0.080397\n",
      "28      html_feat_11    0.073798\n",
      "45      html_feat_28    0.064968\n",
      "80      html_feat_63    0.057693\n",
      "18       html_feat_1    0.055524\n",
      "2   has_product_term    0.047627\n",
      "70      html_feat_53    0.046090\n",
      "39      html_feat_22    0.043840\n",
      "49      html_feat_32    0.033057\n",
      "\n",
      "Example of using the trained model with a new website:\n",
      "{\n",
      "  \"url\": \"https://example-fashion-store.com\",\n",
      "  \"domain\": \"example-fashion-store.com\",\n",
      "  \"selectors\": {\n",
      "    \"product_containers\": [\n",
      "      \"section.products-container\",\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section\"\n",
      "      },\n",
      "      \"article.product-container-fashion\",\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section/article[1]\"\n",
      "      },\n",
      "      \"div.product-details\",\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section/article[1]/div\"\n",
      "      }\n",
      "    ],\n",
      "    \"price_elements\": [\n",
      "      \"div.price-fashion\",\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section/article[1]/div/div[1]\"\n",
      "      }\n",
      "    ],\n",
      "    \"name_elements\": [\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section/article[1]/div/h3\"\n",
      "      }\n",
      "    ],\n",
      "    \"image_elements\": [\n",
      "      {\n",
      "        \"xpath\": \"//body/main/section/article[1]/figure/img\"\n",
      "      }\n",
      "    ],\n",
      "    \"button_elements\": []\n",
      "  },\n",
      "  \"patterns\": {\n",
      "    \"container_class\": \"product-container-fashion\",\n",
      "    \"price_class\": \"price-fashion\",\n",
      "    \"name_tag\": \"h3\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Integration with Flask app:\n",
      "\n",
      "Model Training and Integration Complete!\n",
      "\n",
      "The machine learning model can now be used to analyze new web pages and extract product information.\n",
      "Key benefits:\n",
      "1. Adapts to different HTML structures across websites\n",
      "2. Learns patterns from training data\n",
      "3. Identifies product containers, prices, names, and other elements\n",
      "4. Generates CSS selectors and XPath expressions for extraction\n",
      "\n",
      "To improve the model:\n",
      "1. Train with real-world web pages instead of synthetic data\n",
      "2. Add more features based on HTML structure\n",
      "3. Use more advanced models like neural networks\n",
      "4. Implement active learning to update the model with feedback\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 4  0]\n",
      " [ 0 16]]\n",
      "Confusion matrix visualization saved as 'confusion_matrix.png'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ML Web Scraper Model for E-Commerce Product Analysis\n",
    "# This notebook implements a machine learning pipeline to extract product information\n",
    "# from HTML pages with different structures\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# First, we'll create functions to prepare the training data\n",
    "\n",
    "def download_page(url, timeout=10):\n",
    "    \"\"\"Download HTML content from URL with proper headers\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=timeout)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_domain(url):\n",
    "    \"\"\"Extract the domain from a URL\"\"\"\n",
    "    parsed_uri = urlparse(url)\n",
    "    return parsed_uri.netloc\n",
    "\n",
    "def extract_features_from_tag(tag):\n",
    "    \"\"\"Extract features from a BeautifulSoup tag\"\"\"\n",
    "    features = {\n",
    "        'tag_name': tag.name,\n",
    "        'class': ' '.join(tag.get('class', [])),\n",
    "        'id': tag.get('id', ''),\n",
    "        'text_length': len(tag.get_text(strip=True)),\n",
    "        'has_price': 1 if re.search(r'(\\$|€|£|\\d+\\.\\d{2})', tag.get_text()) else 0,\n",
    "        'has_product_term': 1 if re.search(r'product|item|buy|purchase|cart|shop', tag.get_text().lower()) else 0,\n",
    "        'has_img': 1 if tag.find('img') else 0,\n",
    "        'has_link': 1 if tag.find('a') else 0,\n",
    "        'depth': len(list(tag.parents)),\n",
    "        'child_count': len(tag.contents),\n",
    "        'sibling_count': len(list(tag.next_siblings)) + len(list(tag.previous_siblings))\n",
    "    }\n",
    "    return features\n",
    "\n",
    "def generate_training_data(html_samples, domain_categories):\n",
    "    \"\"\"Generate training data from HTML samples\"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    for idx, (url, html) in enumerate(html_samples.items()):\n",
    "        if not html:\n",
    "            continue\n",
    "            \n",
    "        domain = extract_domain(url)\n",
    "        domain_type = domain_categories.get(domain, 'other')\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Select promising elements for classification\n",
    "        candidates = soup.select('div, li, article, section')\n",
    "        \n",
    "        for tag in candidates:\n",
    "            # Skip very small tags\n",
    "            if len(tag.get_text(strip=True)) < 10:\n",
    "                continue\n",
    "                \n",
    "            features = extract_features_from_tag(tag)\n",
    "            \n",
    "            # Label as product container if it likely contains product info\n",
    "            is_product = 0\n",
    "            text = tag.get_text().lower()\n",
    "            \n",
    "            # Determine if this tag is likely a product container\n",
    "            if (features['has_price'] == 1 and \n",
    "                ('buy' in text or 'add to cart' in text or re.search(r'product|item', tag.get('class', [''])[0] if tag.get('class') else ''))):\n",
    "                is_product = 1\n",
    "                \n",
    "            features['domain_type'] = domain_type\n",
    "            features['is_product'] = is_product\n",
    "            features['html_structure'] = str(tag)[:1000]  # Store part of HTML for reference\n",
    "            \n",
    "            all_data.append(features)\n",
    "    \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# Now let's simulate creating a dataset with annotated training data\n",
    "# In a real-world scenario, you would collect actual HTML from various sites\n",
    "\n",
    "# 1. Download some e-commerce pages for training\n",
    "\n",
    "print(\"Preparing to download sample e-commerce pages for model training...\")\n",
    "\n",
    "# List of popular e-commerce sites and their category\n",
    "ecommerce_urls = {\n",
    "    'https://example-electronics-store.com': 'electronics',\n",
    "    'https://example-bookstore.com': 'books',\n",
    "    'https://example-fashion-store.com': 'fashion',\n",
    "    'https://example-home-goods.com': 'home',\n",
    "    'https://example-general-ecommerce.com': 'general'\n",
    "}\n",
    "\n",
    "# For this notebook, we'll create synthetic data rather than actually downloading\n",
    "# In a real implementation, you would replace this with actual downloads\n",
    "\n",
    "print(\"Using synthetic data for demonstration purposes...\")\n",
    "\n",
    "# Create synthetic HTML structures for different e-commerce types\n",
    "def generate_synthetic_html(domain_type):\n",
    "    \"\"\"Generate synthetic HTML for different types of e-commerce sites\"\"\"\n",
    "    product_class = f\"product-container-{domain_type}\"\n",
    "    price_class = f\"price-{domain_type}\"\n",
    "    \n",
    "    if domain_type == 'electronics':\n",
    "        product_template = f\"\"\"\n",
    "        <div class=\"{product_class}\">\n",
    "            <div class=\"image-container\"><img src=\"product.jpg\" alt=\"Product\"></div>\n",
    "            <h3 class=\"product-title\">Electronics Product</h3>\n",
    "            <div class=\"{price_class}\">$299.99</div>\n",
    "            <div class=\"rating\">★★★★☆</div>\n",
    "            <button class=\"add-to-cart\">Add to Cart</button>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    elif domain_type == 'books':\n",
    "        product_template = f\"\"\"\n",
    "        <li class=\"{product_class}\">\n",
    "            <div class=\"book-cover\"><img src=\"book.jpg\" alt=\"Book\"></div>\n",
    "            <div class=\"book-info\">\n",
    "                <h4>Book Title</h4>\n",
    "                <p class=\"author\">Author Name</p>\n",
    "                <span class=\"{price_class}\">$15.99</span>\n",
    "            </div>\n",
    "            <a href=\"#\" class=\"buy-now\">Buy Now</a>\n",
    "        </li>\n",
    "        \"\"\"\n",
    "    elif domain_type == 'fashion':\n",
    "        product_template = f\"\"\"\n",
    "        <article class=\"{product_class}\">\n",
    "            <figure class=\"product-image\">\n",
    "                <img src=\"fashion.jpg\" alt=\"Fashion item\">\n",
    "            </figure>\n",
    "            <div class=\"product-details\">\n",
    "                <h3>Fashion Item Name</h3>\n",
    "                <div class=\"{price_class}\">$49.95</div>\n",
    "                <div class=\"color-options\">\n",
    "                    <span class=\"color red\"></span>\n",
    "                    <span class=\"color blue\"></span>\n",
    "                </div>\n",
    "            </div>\n",
    "            <button class=\"add-to-bag\">Add to Bag</button>\n",
    "        </article>\n",
    "        \"\"\"\n",
    "    elif domain_type == 'home':\n",
    "        product_template = f\"\"\"\n",
    "        <div class=\"{product_class}\">\n",
    "            <img src=\"home-item.jpg\" alt=\"Home item\">\n",
    "            <h4 class=\"item-name\">Home Decor Item</h4>\n",
    "            <div class=\"item-details\">\n",
    "                <span class=\"{price_class}\">$79.99</span>\n",
    "                <span class=\"availability\">In Stock</span>\n",
    "            </div>\n",
    "            <a href=\"#\" class=\"view-details\">View Details</a>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    else:  # general\n",
    "        product_template = f\"\"\"\n",
    "        <div class=\"{product_class}\">\n",
    "            <div class=\"product-image\">\n",
    "                <img src=\"product.jpg\" alt=\"Product\">\n",
    "            </div>\n",
    "            <div class=\"product-info\">\n",
    "                <h3>Product Name</h3>\n",
    "                <div class=\"{price_class}\">$39.99</div>\n",
    "                <div class=\"product-rating\">4.5/5</div>\n",
    "            </div>\n",
    "            <button class=\"buy-button\">Buy Now</button>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    \n",
    "    # Create a page with multiple products\n",
    "    products = \"\"\n",
    "    for i in range(10):\n",
    "        products += product_template.replace('Product Name', f'Product Name {i+1}')\n",
    "    \n",
    "    # Full page template\n",
    "    full_page = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>{domain_type.capitalize()} Store</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <header>\n",
    "            <nav>\n",
    "                <ul>\n",
    "                    <li><a href=\"#\">Home</a></li>\n",
    "                    <li><a href=\"#\">Products</a></li>\n",
    "                    <li><a href=\"#\">About</a></li>\n",
    "                    <li><a href=\"#\">Contact</a></li>\n",
    "                </ul>\n",
    "            </nav>\n",
    "        </header>\n",
    "        <main>\n",
    "            <h1>Welcome to our {domain_type.capitalize()} Store</h1>\n",
    "            <div class=\"filters\">\n",
    "                <select>\n",
    "                    <option>Sort by Price</option>\n",
    "                    <option>Sort by Popularity</option>\n",
    "                </select>\n",
    "            </div>\n",
    "            <section class=\"products-container\">\n",
    "                {products}\n",
    "            </section>\n",
    "        </main>\n",
    "        <footer>\n",
    "            <p>© 2025 {domain_type.capitalize()} Store. All rights reserved.</p>\n",
    "        </footer>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "    return full_page\n",
    "\n",
    "# Generate synthetic HTML for each domain type\n",
    "html_samples = {}\n",
    "domain_categories = {}\n",
    "\n",
    "for url, category in ecommerce_urls.items():\n",
    "    domain = extract_domain(url)\n",
    "    html_samples[url] = generate_synthetic_html(category)\n",
    "    domain_categories[domain] = category\n",
    "\n",
    "print(f\"Generated synthetic HTML for {len(html_samples)} e-commerce site types\")\n",
    "\n",
    "# Generate training data from our synthetic HTML\n",
    "print(\"Generating training features from HTML structures...\")\n",
    "training_data = generate_training_data(html_samples, domain_categories)\n",
    "\n",
    "print(f\"Generated {len(training_data)} training samples\")\n",
    "print(f\"Positive examples (product containers): {training_data['is_product'].sum()}\")\n",
    "print(f\"Negative examples (non-product elements): {len(training_data) - training_data['is_product'].sum()}\")\n",
    "\n",
    "# Feature engineering - convert categorical variables to numerical\n",
    "# Text features can be processed with TF-IDF\n",
    "print(\"Performing feature engineering...\")\n",
    "\n",
    "# Process tag structure with TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "html_features = vectorizer.fit_transform(training_data['html_structure'])\n",
    "\n",
    "# One-hot encode domain type\n",
    "domain_dummies = pd.get_dummies(training_data['domain_type'], prefix='domain')\n",
    "\n",
    "# One-hot encode tag_name\n",
    "tag_dummies = pd.get_dummies(training_data['tag_name'], prefix='tag')\n",
    "\n",
    "# Combine all features\n",
    "features = pd.concat([\n",
    "    # Only include numeric features\n",
    "    training_data[['text_length', 'has_price', 'has_product_term', 'has_img', 'has_link', \n",
    "                   'depth', 'child_count', 'sibling_count']],\n",
    "    # Add encoded categorical features\n",
    "    domain_dummies,\n",
    "    tag_dummies,\n",
    "    pd.DataFrame(html_features.toarray(), columns=[f\"html_feat_{i}\" for i in range(html_features.shape[1])])\n",
    "], axis=1)\n",
    "\n",
    "if 'class' in training_data.columns:\n",
    "    class_vectorizer = TfidfVectorizer(max_features=50)\n",
    "    class_features = class_vectorizer.fit_transform(training_data['class'].fillna(''))\n",
    "    features = pd.concat([features, \n",
    "                         pd.DataFrame(class_features.toarray(), \n",
    "                                     columns=[f\"class_feat_{i}\" for i in range(class_features.shape[1])])], \n",
    "                         axis=1)\n",
    "\n",
    "if 'id' in training_data.columns:\n",
    "    # For id, just check if present\n",
    "    features['has_id'] = training_data['id'].apply(lambda x: 0 if pd.isna(x) or x == '' else 1)\n",
    "\n",
    "# Prepare for training\n",
    "X = features\n",
    "y = training_data['is_product']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "print(\"Training Random Forest classifier...\")\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the model and vectorizer\n",
    "print(\"Saving model and feature engineering components...\")\n",
    "joblib.dump(model, 'product_container_model.pkl')\n",
    "joblib.dump(vectorizer, 'html_vectorizer.pkl')\n",
    "\n",
    "# Feature importance analysis\n",
    "feature_importances = pd.DataFrame({\n",
    "    'feature': features.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 most important features:\")\n",
    "print(feature_importances.head(10))\n",
    "\n",
    "# Now define a function to use the trained model to analyze new pages\n",
    "\n",
    "def extract_product_tags(html, url):\n",
    "    \"\"\"Use trained model to extract product containers from a new page\"\"\"\n",
    "    domain = extract_domain(url)\n",
    "    domain_type = domain_categories.get(domain, 'other')  \n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    candidates = soup.select('div, li, article, section')\n",
    "    \n",
    "    results = {\n",
    "        'product_containers': [],\n",
    "        'price_tags': [],\n",
    "        'name_tags': [],\n",
    "        'image_tags': [],\n",
    "        'button_tags': []\n",
    "    }\n",
    "    \n",
    "    for tag in candidates:\n",
    "        # Skip very small tags\n",
    "        if len(tag.get_text(strip=True)) < 10:\n",
    "            continue\n",
    "            \n",
    "        features = extract_features_from_tag(tag)\n",
    "        features['domain_type'] = domain_type\n",
    "        features['html_structure'] = str(tag)[:1000]\n",
    "        \n",
    "        # Convert to DataFrame for prediction\n",
    "        tag_df = pd.DataFrame([features])\n",
    "        \n",
    "        # Process HTML with vectorizer\n",
    "        html_features = vectorizer.transform([features['html_structure']])\n",
    "        \n",
    "        # One-hot encode domain type (need to match training data structure)\n",
    "        domain_cols = [f\"domain_{cat}\" for cat in ecommerce_urls.values()]\n",
    "        domain_vals = {col: 1 if col == f\"domain_{domain_type}\" else 0 for col in domain_cols}\n",
    "        domain_df = pd.DataFrame([domain_vals])\n",
    "        \n",
    "        # Combine features (ensure same structure as training data)\n",
    "        tag_features = pd.concat([\n",
    "            tag_df.drop(['html_structure', 'domain_type', 'is_product'], axis=1, errors='ignore'),\n",
    "            domain_df,\n",
    "            pd.DataFrame(html_features.toarray(), columns=[f\"html_feat_{i}\" for i in range(html_features.shape[1])])\n",
    "        ], axis=1)\n",
    "        \n",
    "        # Ensure columns match training data\n",
    "        missing_cols = set(X.columns) - set(tag_features.columns)\n",
    "        for col in missing_cols:\n",
    "            tag_features[col] = 0\n",
    "        \n",
    "        # Reorder columns to match training data\n",
    "        tag_features = tag_features[X.columns]\n",
    "        \n",
    "        # Predict if this tag is a product container\n",
    "        prediction = model.predict(tag_features)[0]\n",
    "        \n",
    "        if prediction == 1:\n",
    "            # Add this tag to product containers\n",
    "            tag_signature = {\n",
    "                'tag': tag.name,\n",
    "                'classes': tag.get('class', []),\n",
    "                'id': tag.get('id', ''),\n",
    "                'attributes': {k: v for k, v in tag.attrs.items() if k not in ['class', 'id']},\n",
    "                'xpath': generate_xpath(tag)\n",
    "            }\n",
    "            results['product_containers'].append(tag_signature)\n",
    "            \n",
    "            # Find price elements within this container\n",
    "            price_elements = tag.select('.price, [class*=price], .amount, [class*=amount]')\n",
    "            for price_el in price_elements:\n",
    "                if re.search(r'(\\$|€|£|\\d+\\.\\d{2})', price_el.get_text()):\n",
    "                    price_sig = {\n",
    "                        'tag': price_el.name,\n",
    "                        'classes': price_el.get('class', []),\n",
    "                        'id': price_el.get('id', ''),\n",
    "                        'xpath': generate_xpath(price_el)\n",
    "                    }\n",
    "                    results['price_tags'].append(price_sig)\n",
    "            \n",
    "            # Find product name elements\n",
    "            name_elements = tag.select('h1, h2, h3, h4, .title, .name, [class*=title], [class*=name]')\n",
    "            for name_el in name_elements:\n",
    "                if 5 < len(name_el.get_text(strip=True)) < 100:\n",
    "                    name_sig = {\n",
    "                        'tag': name_el.name,\n",
    "                        'classes': name_el.get('class', []),\n",
    "                        'id': name_el.get('id', ''),\n",
    "                        'xpath': generate_xpath(name_el)\n",
    "                    }\n",
    "                    results['name_tags'].append(name_sig)\n",
    "                    \n",
    "            # Find product image elements\n",
    "            img_elements = tag.select('img')\n",
    "            for img_el in img_elements:\n",
    "                img_sig = {\n",
    "                    'tag': img_el.name,\n",
    "                    'classes': img_el.get('class', []),\n",
    "                    'id': img_el.get('id', ''),\n",
    "                    'src': img_el.get('src', ''),\n",
    "                    'alt': img_el.get('alt', ''),\n",
    "                    'xpath': generate_xpath(img_el)\n",
    "                }\n",
    "                results['image_tags'].append(img_sig)\n",
    "                \n",
    "            # Find button elements (add to cart, buy now, etc.)\n",
    "            button_elements = tag.select('button, .button, [class*=button], .btn, [class*=btn], a[href*=cart], a[href*=buy]')\n",
    "            for btn_el in button_elements:\n",
    "                btn_text = btn_el.get_text().lower()\n",
    "                if 'cart' in btn_text or 'buy' in btn_text or 'purchase' in btn_text:\n",
    "                    btn_sig = {\n",
    "                        'tag': btn_el.name,\n",
    "                        'classes': btn_el.get('class', []),\n",
    "                        'id': btn_el.get('id', ''),\n",
    "                        'text': btn_el.get_text(strip=True),\n",
    "                        'xpath': generate_xpath(btn_el)\n",
    "                    }\n",
    "                    results['button_tags'].append(btn_sig)\n",
    "    \n",
    "    # Analyze and find patterns in collected data\n",
    "    results['patterns'] = analyze_patterns(results)\n",
    "    return results\n",
    "\n",
    "def generate_xpath(element):\n",
    "    \"\"\"Generate an XPath for the given element\"\"\"\n",
    "    components = []\n",
    "    child = element\n",
    "    \n",
    "    for parent in element.parents:\n",
    "        siblings = parent.find_all(child.name, recursive=False)\n",
    "        siblings_count = 0\n",
    "        \n",
    "        if len(siblings) > 1:\n",
    "            for sibling in siblings:\n",
    "                if sibling == child:\n",
    "                    components.insert(0, f'{child.name}[{siblings_count+1}]')\n",
    "                    break\n",
    "                siblings_count += 1\n",
    "        else:\n",
    "            components.insert(0, child.name)\n",
    "            \n",
    "        child = parent\n",
    "        \n",
    "        if parent.name == 'html':\n",
    "            break\n",
    "            \n",
    "    return '//' + '/'.join(components)\n",
    "\n",
    "def analyze_patterns(extracted_data):\n",
    "    \"\"\"Analyze extracted elements to find common patterns\"\"\"\n",
    "    patterns = {}\n",
    "    \n",
    "    # Analyze product containers\n",
    "    if extracted_data['product_containers']:\n",
    "        container_classes = []\n",
    "        for container in extracted_data['product_containers']:\n",
    "            container_classes.extend(container['classes'])\n",
    "        \n",
    "        class_counts = pd.Series(container_classes).value_counts()\n",
    "        if not class_counts.empty:\n",
    "            patterns['container_class'] = class_counts.index[0]\n",
    "    \n",
    "    # Analyze price elements\n",
    "    if extracted_data['price_tags']:\n",
    "        price_classes = []\n",
    "        for price in extracted_data['price_tags']:\n",
    "            price_classes.extend(price['classes'])\n",
    "        \n",
    "        class_counts = pd.Series(price_classes).value_counts()\n",
    "        if not class_counts.empty:\n",
    "            patterns['price_class'] = class_counts.index[0]\n",
    "    \n",
    "    # Similar analysis for other elements\n",
    "    # Name patterns\n",
    "    if extracted_data['name_tags']:\n",
    "        name_tags = [item['tag'] for item in extracted_data['name_tags']]\n",
    "        tag_counts = pd.Series(name_tags).value_counts()\n",
    "        if not tag_counts.empty:\n",
    "            patterns['name_tag'] = tag_counts.index[0]\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Create a function to integrate with the Flask app\n",
    "\n",
    "def analyze_website_structure(url, html_content):\n",
    "    \"\"\"\n",
    "    Main function to analyze a website and extract product information structure\n",
    "    \n",
    "    Args:\n",
    "        url: The URL of the website\n",
    "        html_content: HTML content of the page\n",
    "        \n",
    "    Returns:\n",
    "        dict: Structured information about how to extract product data\n",
    "    \"\"\"\n",
    "    # Load the trained model and vectorizer\n",
    "    try:\n",
    "        model = joblib.load('product_container_model.pkl')\n",
    "        vectorizer = joblib.load('html_vectorizer.pkl')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model files not found. Please train the model first.\")\n",
    "        return None\n",
    "    \n",
    "    # Extract product elements and patterns\n",
    "    extraction_results = extract_product_tags(html_content, url)\n",
    "    \n",
    "    # Generate selectors for each element type\n",
    "    selectors = {\n",
    "        'product_containers': generate_selectors(extraction_results['product_containers']),\n",
    "        'price_elements': generate_selectors(extraction_results['price_tags']),\n",
    "        'name_elements': generate_selectors(extraction_results['name_tags']),\n",
    "        'image_elements': generate_selectors(extraction_results['image_tags']),\n",
    "        'button_elements': generate_selectors(extraction_results['button_tags'])\n",
    "    }\n",
    "    \n",
    "    # Create extraction rules\n",
    "    extraction_rules = {\n",
    "        'url': url,\n",
    "        'domain': extract_domain(url),\n",
    "        'selectors': selectors,\n",
    "        'patterns': extraction_results['patterns']\n",
    "    }\n",
    "    \n",
    "    return extraction_rules\n",
    "\n",
    "def generate_selectors(elements):\n",
    "    \"\"\"Generate CSS selectors for the given elements\"\"\"\n",
    "    if not elements:\n",
    "        return []\n",
    "    \n",
    "    selectors = []\n",
    "    \n",
    "    for element in elements:\n",
    "        # Try class-based selector first\n",
    "        if element['classes']:\n",
    "            class_selector = f\"{element['tag']}.{'.'.join(element['classes'])}\"\n",
    "            selectors.append(class_selector)\n",
    "            \n",
    "        # Try ID-based selector\n",
    "        if element['id']:\n",
    "            id_selector = f\"#{element['id']}\"\n",
    "            selectors.append(id_selector)\n",
    "            \n",
    "        # Add XPath as fallback\n",
    "        if 'xpath' in element:\n",
    "            selectors.append({'xpath': element['xpath']})\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    unique_selectors = []\n",
    "    for selector in selectors:\n",
    "        if selector not in unique_selectors:\n",
    "            unique_selectors.append(selector)\n",
    "    \n",
    "    return unique_selectors\n",
    "\n",
    "# Example usage of the model with the Flask app\n",
    "print(\"\\nExample of using the trained model with a new website:\")\n",
    "test_url = \"https://example-fashion-store.com\"\n",
    "test_html = generate_synthetic_html('fashion')  # For demonstration\n",
    "\n",
    "extraction_rules = analyze_website_structure(test_url, test_html)\n",
    "print(json.dumps(extraction_rules, indent=2))\n",
    "\n",
    "# Integration with Flask app\n",
    "print(\"\\nIntegration with Flask app:\")\n",
    "\n",
    "# Conclusion\n",
    "print(\"\\nModel Training and Integration Complete!\")\n",
    "print(\"\"\"\n",
    "The machine learning model can now be used to analyze new web pages and extract product information.\n",
    "Key benefits:\n",
    "1. Adapts to different HTML structures across websites\n",
    "2. Learns patterns from training data\n",
    "3. Identifies product containers, prices, names, and other elements\n",
    "4. Generates CSS selectors and XPath expressions for extraction\n",
    "\n",
    "To improve the model:\n",
    "1. Train with real-world web pages instead of synthetic data\n",
    "2. Add more features based on HTML structure\n",
    "3. Use more advanced models like neural networks\n",
    "4. Implement active learning to update the model with feedback\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Add this import at the top with your other imports\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add this code after your existing classification_report evaluation\n",
    "# (right after the line: print(classification_report(y_test, y_pred)))\n",
    "\n",
    "# Generate and display confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Create a visual representation of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Not Product', 'Product'])\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "plt.title('Confusion Matrix for Product Detection')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Confusion matrix visualization saved as 'confusion_matrix.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
